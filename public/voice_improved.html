<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>VoiceBot AI - Enhanced Voice Chat</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }

        .unified-container {
            width: 100%;
            max-width: 1000px;
            height: 90vh;
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(10px);
            border-radius: 24px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            display: flex;
            flex-direction: column;
            overflow: hidden;
        }

        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 20px 30px;
            display: flex;
            align-items: center;
            justify-content: space-between;
        }

        .header-left {
            display: flex;
            align-items: center;
            gap: 16px;
        }

        .avatar {
            width: 48px;
            height: 48px;
            background: rgba(255, 255, 255, 0.2);
            border-radius: 12px;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 24px;
        }

        .header-info h1 {
            font-size: 22px;
            font-weight: 600;
            margin-bottom: 4px;
        }

        .header-info p {
            font-size: 13px;
            opacity: 0.9;
        }

        .status-dot {
            width: 8px;
            height: 8px;
            background: #4ade80;
            border-radius: 50%;
            display: inline-block;
            margin-right: 6px;
            animation: pulse 2s infinite;
        }

        @keyframes pulse {

            0%,
            100% {
                opacity: 1;
            }

            50% {
                opacity: 0.5;
            }
        }

        .mic-selector {
            background: rgba(255, 255, 255, 0.1);
            padding: 8px 12px;
            border-radius: 8px;
            font-size: 13px;
        }

        .mic-selector select {
            background: rgba(255, 255, 255, 0.2);
            border: none;
            color: white;
            padding: 4px 8px;
            border-radius: 4px;
            font-size: 12px;
            cursor: pointer;
        }

        .mic-selector select option {
            background: #667eea;
            color: white;
        }

        .chat-messages {
            flex: 1;
            overflow-y: auto;
            padding: 24px;
            background: #f8f9fa;
            display: flex;
            flex-direction: column;
            gap: 16px;
        }

        .message {
            display: flex;
            gap: 12px;
            animation: slideIn 0.3s ease-out;
        }

        @keyframes slideIn {
            from {
                opacity: 0;
                transform: translateY(10px);
            }

            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .message.user {
            flex-direction: row-reverse;
        }

        .message-avatar {
            width: 36px;
            height: 36px;
            border-radius: 10px;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 18px;
            flex-shrink: 0;
        }

        .message.user .message-avatar {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }

        .message.ai .message-avatar {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            color: white;
        }

        .message-content {
            max-width: 70%;
            padding: 14px 18px;
            border-radius: 16px;
            line-height: 1.5;
            word-wrap: break-word;
        }

        .message.user .message-content {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border-bottom-right-radius: 4px;
        }

        .message.ai .message-content {
            background: white;
            color: #1f2937;
            border-bottom-left-radius: 4px;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        .message-time {
            font-size: 11px;
            opacity: 0.7;
            margin-top: 6px;
        }

        .diagnostic-link {
            display: inline-block;
            margin-top: 8px;
            padding: 6px 12px;
            background: #3b82f6;
            color: white;
            text-decoration: none;
            border-radius: 6px;
            font-size: 12px;
            font-weight: 600;
        }

        .diagnostic-link:hover {
            background: #2563eb;
        }

        .input-section {
            background: white;
            padding: 20px;
            border-top: 1px solid #e5e7eb;
        }

        .input-modes {
            display: flex;
            gap: 12px;
            margin-bottom: 12px;
        }

        .mode-button {
            padding: 8px 16px;
            background: #f3f4f6;
            border: 2px solid transparent;
            border-radius: 10px;
            font-size: 14px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.2s;
            display: flex;
            align-items: center;
            gap: 6px;
        }

        .mode-button.active {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border-color: #667eea;
        }

        .voice-controls {
            display: none;
            width: 100%;
        }

        .voice-controls.active {
            display: block;
        }

        .voice-input-container {
            display: flex;
            gap: 12px;
            align-items: center;
            width: 100%;
        }

        .voice-mic-btn {
            width: 60px;
            height: 60px;
            min-width: 60px;
            border-radius: 50%;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border: none;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 28px;
            color: white;
            transition: all 0.3s ease;
            box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4);
        }

        .voice-mic-btn:hover {
            transform: scale(1.05);
            box-shadow: 0 6px 16px rgba(102, 126, 234, 0.6);
        }

        .voice-mic-btn.recording {
            background: linear-gradient(135deg, #ef4444 0%, #dc2626 100%);
            animation: recordingPulse 1.5s ease-in-out infinite;
        }

        @keyframes recordingPulse {

            0%,
            100% {
                box-shadow: 0 4px 12px rgba(239, 68, 68, 0.4);
            }

            50% {
                box-shadow: 0 8px 24px rgba(239, 68, 68, 0.8);
            }
        }

        .voice-input-area {
            flex: 1;
            padding: 14px 18px;
            border: 2px solid #e5e7eb;
            border-radius: 12px;
            background: white;
            min-height: 60px;
            display: flex;
            flex-direction: column;
            justify-content: center;
            gap: 8px;
            transition: all 0.2s;
        }

        .voice-input-area.recording {
            border-color: #ef4444;
            background: #fef2f2;
        }

        .voice-status-text {
            font-size: 14px;
            color: #6b7280;
            text-align: center;
            line-height: 1.4;
        }

        .audio-level-meter {
            height: 6px;
            background: #e5e7eb;
            border-radius: 3px;
            overflow: hidden;
            margin-top: 6px;
        }

        .audio-level-fill {
            height: 100%;
            background: linear-gradient(90deg, #10b981 0%, #059669 100%);
            width: 0%;
            transition: width 0.1s;
            border-radius: 3px;
        }

        .text-controls {
            display: none;
            gap: 12px;
            width: 100%;
        }

        .text-controls.active {
            display: flex;
        }

        #messageInput {
            flex: 1;
            padding: 14px 18px;
            border: 2px solid #e5e7eb;
            border-radius: 12px;
            font-size: 15px;
            font-family: inherit;
            resize: none;
            max-height: 120px;
            transition: border-color 0.2s;
        }

        #messageInput:focus {
            outline: none;
            border-color: #667eea;
        }

        #sendButton {
            padding: 14px 28px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border: none;
            border-radius: 12px;
            font-size: 15px;
            font-weight: 600;
            cursor: pointer;
            transition: transform 0.2s;
        }

        #sendButton:hover {
            transform: translateY(-2px);
        }

        .typing-indicator {
            display: none;
            padding: 14px 18px;
            background: white;
            border-radius: 16px;
            border-bottom-left-radius: 4px;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
            width: fit-content;
        }

        .typing-indicator.active {
            display: block;
        }

        .typing-dots {
            display: flex;
            gap: 6px;
        }

        .typing-dots span {
            width: 8px;
            height: 8px;
            background: #667eea;
            border-radius: 50%;
            animation: typing 1.4s infinite;
        }

        .typing-dots span:nth-child(2) {
            animation-delay: 0.2s;
        }

        .typing-dots span:nth-child(3) {
            animation-delay: 0.4s;
        }

        @keyframes typing {

            0%,
            60%,
            100% {
                opacity: 0.3;
                transform: translateY(0);
            }

            30% {
                opacity: 1;
                transform: translateY(-6px);
            }
        }
    </style>
</head>

<body>
    <div class="unified-container">
        <div class="header">
            <div class="header-left">
                <div class="avatar">ü§ñ</div>
                <div class="header-info">
                    <h1>VoiceBot AI - Enhanced</h1>
                    <p><span class="status-dot"></span>Voice & Text Chat</p>
                </div>
            </div>
            <div class="mic-selector" id="micSelectorContainer" style="display: none;">
                <label>üé§ Microphone:</label>
                <select id="micSelect"></select>
            </div>
        </div>

        <div class="chat-messages" id="chatMessages">
            <div class="message ai">
                <div class="message-avatar">ü§ñ</div>
                <div class="message-content">
                    üëã <strong>Welcome to Enhanced VoiceBot!</strong><br><br>

                    <strong>Voice Chat:</strong> Click the microphone and speak clearly<br>
                    <strong>Text Chat:</strong> Type your message<br><br>

                    <strong>‚ö†Ô∏è Voice Issue?</strong> If voice doesn't work, click here:
                    <a href="/static/mic_diagnostic_advanced.html" target="_blank" class="diagnostic-link">
                        üî¨ Run Microphone Diagnostic
                    </a>
                    <div class="message-time" id="welcomeTime"></div>
                </div>
            </div>
        </div>

        <div class="input-section">
            <!-- Mode Selection -->
            <div class="input-modes">
                <button class="mode-button" id="textModeBtn" onclick="switchMode('text')">
                    üí¨ Text Chat
                </button>
                <button class="mode-button active" id="voiceModeBtn" onclick="switchMode('voice')">
                    üéôÔ∏è Voice Chat
                </button>
            </div>

            <!-- Voice Controls -->
            <div class="voice-controls active" id="voiceControls">
                <div class="voice-input-container">
                    <button class="voice-mic-btn" id="voiceButton" onclick="toggleRecording()">
                        <span id="voiceIcon">üé§</span>
                    </button>
                    <div class="voice-input-area" id="voiceInputArea">
                        <div class="voice-status-text" id="voiceStatus">Click microphone to start speaking</div>
                        <div class="audio-level-meter">
                            <div class="audio-level-fill" id="audioLevelFill"></div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Text Controls -->
            <div class="text-controls" id="textControls">
                <textarea id="messageInput" placeholder="Type your message here..." rows="1"
                    onkeypress="handleKeyPress(event)"></textarea>
                <button id="sendButton" onclick="sendTextMessage()">
                    <span>Send ‚úàÔ∏è</span>
                </button>
            </div>
        </div>
    </div>

    <script>
        const API_URL = 'http://localhost:9011/api/v1';
        let conversationId = `conv_${Date.now()}`;
        let currentMode = 'voice';

        // Voice variables
        let isRecording = false;
        let recognition = null;
        let audioContext = null;
        let analyser = null;
        let microphone = null;
        let currentStream = null;
        let audioLevelInterval = null;
        let availableMicrophones = [];
        let selectedMicId = null;
        let voiceFailureCount = 0;

        // Initialize
        window.addEventListener('load', async () => {
            document.getElementById('welcomeTime').textContent = getCurrentTime();
            await detectMicrophones();
        });

        function getCurrentTime() {
            const now = new Date();
            return now.toLocaleTimeString('en-US', {
                hour: '2-digit',
                minute: '2-digit',
                second: '2-digit'
            });
        }

        // Detect available microphones
        async function detectMicrophones() {
            try {
                // Request permission first
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                stream.getTracks().forEach(track => track.stop());

                // Enumerate devices
                const devices = await navigator.mediaDevices.enumerateDevices();
                availableMicrophones = devices.filter(d => d.kind === 'audioinput');

                if (availableMicrophones.length > 1) {
                    const select = document.getElementById('micSelect');
                    select.innerHTML = '';

                    availableMicrophones.forEach((mic, index) => {
                        const option = document.createElement('option');
                        option.value = mic.deviceId;
                        option.text = mic.label || `Microphone ${index + 1}`;
                        select.appendChild(option);
                    });

                    document.getElementById('micSelectorContainer').style.display = 'block';
                    console.log(`‚úÖ Found ${availableMicrophones.length} microphones`);
                }

                selectedMicId = availableMicrophones[0]?.deviceId;

            } catch (error) {
                console.error('Microphone detection error:', error);
            }
        }

        // Update selected microphone
        document.getElementById('micSelect')?.addEventListener('change', (e) => {
            selectedMicId = e.target.value;
            console.log('Microphone changed:', selectedMicId);
        });

        // Switch between voice and text modes
        function switchMode(mode) {
            currentMode = mode;

            if (mode === 'voice') {
                document.getElementById('voiceModeBtn').classList.add('active');
                document.getElementById('textModeBtn').classList.remove('active');
                document.getElementById('voiceControls').classList.add('active');
                document.getElementById('textControls').classList.remove('active');
            } else {
                document.getElementById('textModeBtn').classList.add('active');
                document.getElementById('voiceModeBtn').classList.remove('active');
                document.getElementById('textControls').classList.add('active');
                document.getElementById('voiceControls').classList.remove('active');
                document.getElementById('messageInput').focus();
            }
        }

        // Voice Recording Functions
        async function toggleRecording() {
            if (!isRecording) {
                await startRecording();
            } else {
                await stopRecording();
            }
        }

        async function startRecording() {
            try {
                // Check browser support
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

                if (!SpeechRecognition) {
                    showVoiceError('Speech recognition not supported. Using text mode.', true);
                    return;
                }

                // Get microphone stream with selected device
                const constraints = {
                    audio: {
                        deviceId: selectedMicId ? { exact: selectedMicId } : undefined,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                };

                currentStream = await navigator.mediaDevices.getUserMedia(constraints);
                console.log('üé§ Microphone access granted');

                // Setup audio level monitoring
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const source = audioContext.createMediaStreamSource(currentStream);
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 2048;
                analyser.smoothingTimeConstant = 0.8;
                source.connect(analyser);

                const dataArray = new Uint8Array(analyser.frequencyBinCount);

                // Monitor audio levels
                audioLevelInterval = setInterval(() => {
                    if (!analyser) return;
                    analyser.getByteFrequencyData(dataArray);
                    const average = dataArray.reduce((a, b) => a + b) / dataArray.length;
                    const percentage = Math.min(100, (average / 128) * 100);
                    document.getElementById('audioLevelFill').style.width = percentage + '%';
                }, 50);

                // Setup speech recognition
                recognition = new SpeechRecognition();
                recognition.continuous = true;
                recognition.interimResults = true;
                recognition.lang = 'en-US';
                recognition.maxAlternatives = 1;

                let finalTranscript = '';
                let lastSpeechTime = Date.now();
                let hasReceivedSpeech = false;
                let recognitionStartTime = Date.now();

                recognition.onstart = () => {
                    recognitionStartTime = Date.now();
                    console.log('‚úÖ Speech recognition started');
                    isRecording = true;
                    document.getElementById('voiceButton').classList.add('recording');
                    document.getElementById('voiceIcon').textContent = '‚èπÔ∏è';
                    document.getElementById('voiceInputArea').classList.add('recording');
                    document.getElementById('voiceStatus').innerHTML = 'üé§ <strong>Listening...</strong> Speak clearly!';
                };

                recognition.onresult = (event) => {
                    hasReceivedSpeech = true;
                    let interim = '';

                    for (let i = event.resultIndex; i < event.results.length; i++) {
                        const transcript = event.results[i][0].transcript;
                        if (event.results[i].isFinal) {
                            finalTranscript += transcript + ' ';
                            console.log('‚úÖ Final:', transcript);
                        } else {
                            interim += transcript;
                        }
                    }

                    const display = finalTranscript + (interim ? `<i style="opacity: 0.6;">${interim}</i>` : '');
                    if (display.trim()) {
                        document.getElementById('voiceStatus').innerHTML = `üé§ "${display.trim()}"`;
                    }

                    lastSpeechTime = Date.now();
                };

                recognition.onerror = (event) => {
                    console.error('Speech error:', event.error);
                    stopRecording();

                    if (event.error === 'no-speech') {
                        showVoiceError('No speech detected. Please speak louder and clearer.', false);
                    } else if (event.error === 'audio-capture') {
                        showVoiceError('Microphone error. Check your microphone settings.', true);
                    } else {
                        showVoiceError(`Speech error: ${event.error}`, false);
                    }
                };

                recognition.onend = async () => {
                    const recognitionDuration = Date.now() - recognitionStartTime;
                    console.log(`üîö Recognition ended (${recognitionDuration}ms)`);
                    await stopRecording();

                    const transcript = finalTranscript.trim();

                    if (transcript) {
                        console.log('‚úÖ Processing:', transcript);
                        voiceFailureCount = 0;
                        await processVoiceMessage(transcript, recognitionDuration);
                    } else {
                        if (hasReceivedSpeech) {
                            showVoiceError('Could not understand speech. Try again.', false);
                        } else {
                            showVoiceError('No speech detected. Check microphone or use text chat.', false);
                        }
                        voiceFailureCount++;

                        // Auto-switch to text mode after 3 failures
                        if (voiceFailureCount >= 3) {
                            addMessage('System', '‚ö†Ô∏è Voice recognition has failed 3 times. Switching to text mode for better experience.', 'ai');
                            switchMode('text');
                            voiceFailureCount = 0;
                        }
                    }
                };

                // Start recognition
                recognition.start();

            } catch (error) {
                console.error('Microphone error:', error);
                showVoiceError(getMicrophoneErrorMessage(error), true);
            }
        }

        async function stopRecording() {
            if (recognition) {
                recognition.stop();
                recognition = null;
            }

            if (currentStream) {
                currentStream.getTracks().forEach(track => track.stop());
                currentStream = null;
            }

            if (audioLevelInterval) {
                clearInterval(audioLevelInterval);
                audioLevelInterval = null;
            }

            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }

            isRecording = false;
            document.getElementById('voiceButton').classList.remove('recording');
            document.getElementById('voiceIcon').textContent = 'üé§';
            document.getElementById('voiceInputArea').classList.remove('recording');
            document.getElementById('voiceStatus').textContent = 'Click microphone to start speaking';
            document.getElementById('audioLevelFill').style.width = '0%';
        }

        function showVoiceError(message, suggestDiagnostic) {
            const fullMessage = suggestDiagnostic
                ? `‚ùå ${message} <a href="/static/mic_diagnostic_advanced.html" target="_blank" class="diagnostic-link">üî¨ Run Diagnostic</a>`
                : `‚ùå ${message}`;

            addMessage('System', fullMessage, 'ai');
            document.getElementById('voiceStatus').innerHTML = message;
        }

        function getMicrophoneErrorMessage(error) {
            if (error.name === 'NotAllowedError') {
                return 'Microphone access denied. Please allow microphone in browser settings.';
            } else if (error.name === 'NotFoundError') {
                return 'No microphone found. Please connect a microphone.';
            } else if (error.name === 'NotReadableError') {
                return 'Microphone is in use by another application.';
            }
            return 'Microphone error: ' + error.message;
        }

        async function processVoiceMessage(transcript, recognitionDuration = 0) {
            const totalStartTime = Date.now();

            addMessage('You', transcript, 'user');

            const progressMsg = addMessage('System', 'ü§ñ AI is thinking... (this may take 10-30 seconds)', 'ai');
            showTypingWithProgress();

            try {
                // LLM Processing
                const llmStartTime = Date.now();
                const response = await sendToLLM(transcript);
                const llmDuration = Date.now() - llmStartTime;

                hideTyping();
                removeMessage(progressMsg);

                // Text-to-Speech
                const ttsStartTime = Date.now();
                await speakText(response.response);
                const ttsDuration = Date.now() - ttsStartTime;

                const totalDuration = Date.now() - totalStartTime;

                // Create detailed timing info
                const timingInfo = `
                    <div style="margin-top: 8px; padding: 8px; background: #f3f4f6; border-radius: 6px; font-size: 11px;">
                        <strong>‚è±Ô∏è Timing Breakdown:</strong><br>
                        üé§ Speech Recognition: <strong>${recognitionDuration}ms</strong><br>
                        ü§ñ LLM Processing: <strong>${llmDuration}ms</strong><br>
                        üîä Text-to-Speech: <strong>${ttsDuration}ms</strong><br>
                        ‚ö° Total: <strong>${totalDuration}ms</strong> (${(totalDuration / 1000).toFixed(2)}s)
                    </div>
                `;

                addMessage('AI', response.response + timingInfo, 'ai');

                console.log(`‚úÖ Timing Breakdown:
  üé§ Recognition: ${recognitionDuration}ms
  ü§ñ LLM: ${llmDuration}ms  
  üîä TTS: ${ttsDuration}ms
  ‚ö° Total: ${totalDuration}ms`);

            } catch (error) {
                hideTyping();
                removeMessage(progressMsg);
                console.error('Error:', error);
                addMessage('System', '‚ùå Error: ' + error.message, 'ai');
            }
        }

        // Text Chat Functions
        async function sendTextMessage() {
            const input = document.getElementById('messageInput');
            const message = input.value.trim();

            if (!message) return;

            input.value = '';
            input.style.height = 'auto';

            const totalStartTime = Date.now();
            addMessage('You', message, 'user');
            const progressMsg = addMessage('System', 'ü§ñ AI is thinking... (this may take 10-30 seconds)', 'ai');
            showTyping();

            try {
                const llmStartTime = Date.now();
                const response = await sendToLLM(message);
                const llmDuration = Date.now() - llmStartTime;
                const totalDuration = Date.now() - totalStartTime;

                hideTyping();
                removeMessage(progressMsg);

                // Create timing info for text chat
                const timingInfo = `
                    <div style="margin-top: 8px; padding: 8px; background: #f3f4f6; border-radius: 6px; font-size: 11px;">
                        <strong>‚è±Ô∏è Timing:</strong>
                        ü§ñ LLM Processing: <strong>${llmDuration}ms</strong>
                        ‚Ä¢ Total: <strong>${totalDuration}ms</strong> (${(totalDuration / 1000).toFixed(2)}s)
                    </div>
                `;

                addMessage('AI', response.response + timingInfo, 'ai');
                console.log(`‚úÖ Text response - LLM: ${llmDuration}ms, Total: ${totalDuration}ms`);
            } catch (error) {
                hideTyping();
                removeMessage(progressMsg);
                addMessage('System', '‚ùå Error: ' + error.message, 'ai');
            }
        }

        async function sendToLLM(text) {
            const response = await fetch(`${API_URL}/conversation`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({
                    message: text,
                    conversation_id: conversationId
                })
            });

            if (!response.ok) {
                throw new Error(`API error: ${response.status}`);
            }

            return await response.json();
        }

        async function speakText(text) {
            return new Promise((resolve) => {
                const utterance = new SpeechSynthesisUtterance(text);
                utterance.rate = 1.4;  // 40% faster for quicker responses
                utterance.pitch = 1.0;
                utterance.volume = 1.0;
                utterance.onend = resolve;
                speechSynthesis.speak(utterance);
            });
        }

        function addMessage(sender, text, type, speak = false) {
            const messagesDiv = document.getElementById('chatMessages');
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${type}`;
            messageDiv.dataset.sender = sender; // For removal

            const avatar = type === 'user' ? 'üë§' : 'ü§ñ';

            messageDiv.innerHTML = `
                <div class="message-avatar">${avatar}</div>
                <div class="message-content">
                    ${text}
                    <div class="message-time">${getCurrentTime()}</div>
                </div>
            `;

            messagesDiv.appendChild(messageDiv);
            messagesDiv.scrollTop = messagesDiv.scrollHeight;
            return messageDiv; // Return for removal
        }

        function removeMessage(messageElement) {
            if (messageElement && messageElement.parentNode) {
                messageElement.parentNode.removeChild(messageElement);
            }
        }

        function showTyping() {
            const typing = document.querySelector('.typing-indicator') || createTypingIndicator();
            typing.classList.add('active');
        }

        function showTypingWithProgress() {
            showTyping();
        }

        function hideTyping() {
            const typing = document.querySelector('.typing-indicator');
            if (typing) typing.classList.remove('active');
        }

        function createTypingIndicator() {
            const messagesDiv = document.getElementById('chatMessages');
            const typing = document.createElement('div');
            typing.className = 'typing-indicator';
            typing.innerHTML = `
                <div class="typing-dots">
                    <span></span><span></span><span></span>
                </div>
            `;
            messagesDiv.appendChild(typing);
            return typing;
        }

        function handleKeyPress(event) {
            if (event.key === 'Enter' && !event.shiftKey) {
                event.preventDefault();
                sendTextMessage();
            }
        }
    </script>
</body>

</html>